{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fluorine/PFAS Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "import numpy, sys\n",
    "import wandb\n",
    "from pathlib import Path\n",
    "import torch.optim as optim\n",
    "\n",
    "from massspecgym.data import MassSpecDataset, MassSpecDataModule\n",
    "from massspecgym.data.transforms import SpecTokenizer, MolFingerprinter\n",
    "from massspecgym.models.base import Stage\n",
    "from massspecgym.models.retrieval.base import MassSpecGymModel\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from pytorch_lightning.utilities import grad_norm\n",
    "\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from massspecgym.models.base import Stage\n",
    "from dreams.api import PreTrainedModel\n",
    "from dreams.models.dreams.dreams import DreaMS as DreaMSModel\n",
    "from torchmetrics.classification import BinaryPrecision, BinaryRecall, BinaryAccuracy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "numpy.set_printoptions(threshold=sys.maxsize)\n",
    "torch.set_float32_matmul_precision('high')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0]\n",
      "[0 0 1 0]\n",
      "[0 0 0 0]\n",
      "[0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from massspecgym.data.transforms import MolToHalogensVector, MolToPFASVector\n",
    "\n",
    "# Example usage\n",
    "checker = MolToHalogensVector() # creating an object of type MolToHalogensVector\n",
    "smiles_string = \"CC(F)(F)F\"\n",
    "halogen_vector = checker.from_smiles(smiles_string)\n",
    "print(halogen_vector)\n",
    "# Example usage\n",
    "smiles_string = \"CCBr\"\n",
    "halogen_vector = checker.from_smiles(smiles_string)\n",
    "print(halogen_vector)\n",
    "\n",
    "checker = MolToPFASVector()\n",
    "smiles_string = \"CC(F)(F)F\"\n",
    "halogen_vector = checker.from_smiles(smiles_string)\n",
    "print(halogen_vector)\n",
    "\n",
    "# Example usage\n",
    "smiles_string = \"CCBr\"\n",
    "halogen_vector = checker.from_smiles(smiles_string)\n",
    "print(halogen_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 0\n"
     ]
    }
   ],
   "source": [
    "pl.seed_everything(0)\n",
    "\n",
    "DEBUG = False\n",
    "\n",
    "if DEBUG:\n",
    "    mgf_pth = Path(\"/teamspace/studios/this_studio/MassSpecGym/data/debug/example_5_spectra.mgf\")\n",
    "    split_pth = Path(\"/teamspace/studios/this_studio/MassSpecGym/data/debug/example_5_spectra_split.tsv\")\n",
    "else:\n",
    "    mgf_pth = None\n",
    "    split_pth = None\n",
    "\n",
    "# Check if MPS is available, otherwise use CUDA\n",
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "else:\n",
    "    mps_device = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removed adduct due to a str error\n",
    "class TestMassSpecDataset(MassSpecDataset):\n",
    "\n",
    "    def __getitem__(\n",
    "        self, i: int, transform_spec: bool = True, transform_mol: bool = True\n",
    "    ) -> dict:\n",
    "        spec = self.spectra[i]\n",
    "        metadata = self.metadata.iloc[i]\n",
    "        mol = metadata[\"smiles\"]\n",
    "\n",
    "        # Apply all transformations to the spectrum\n",
    "        item = {}\n",
    "        if transform_spec and self.spec_transform:\n",
    "            if isinstance(self.spec_transform, dict):\n",
    "                for key, transform in self.spec_transform.items():\n",
    "                    item[key] = transform(spec) if transform is not None else spec\n",
    "            else:\n",
    "                item[\"spec\"] = self.spec_transform(spec)\n",
    "        else:\n",
    "            item[\"spec\"] = spec\n",
    "\n",
    "        # Apply all transformations to the molecule\n",
    "        if transform_mol and self.mol_transform:\n",
    "            if isinstance(self.mol_transform, dict):\n",
    "                for key, transform in self.mol_transform.items():\n",
    "                    item[key] = transform(mol) if transform is not None else mol\n",
    "            else:\n",
    "                item[\"mol\"] = self.mol_transform(mol)\n",
    "        else:\n",
    "            item[\"mol\"] = mol\n",
    "\n",
    "        # Add other metadata to the item\n",
    "        item.update({\n",
    "            k: metadata[k] for k in [\"precursor_mz\"] # removed adduct due to a str error\n",
    "        })\n",
    "\n",
    "        if self.return_mol_freq:\n",
    "            item[\"mol_freq\"] = metadata[\"mol_freq\"]\n",
    "\n",
    "        if self.return_identifier:\n",
    "            item[\"identifier\"] = metadata[\"identifier\"]\n",
    "\n",
    "        # TODO: this should be refactored\n",
    "        for k, v in item.items():\n",
    "            if not isinstance(v, str):\n",
    "                item[k] = torch.as_tensor(v, dtype=self.dtype)\n",
    "        \n",
    "        return item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting PFAS from mzML files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from massspecgym.models.pfas import HalogenDetectorDreamsTest\n",
    "ckpt_path = '/teamspace/studios/this_studio/HalogenDetection-FocalLoss-MergedMassSpecNIST20_NISTNew_NormalPFAS/ujmvyfxm/checkpoints/epoch=0-step=9285.ckpt'\n",
    "model = HalogenDetectorDreamsTest.load_from_checkpoint(ckpt_path)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from dreams.utils.data import MSData\n",
    "from dreams.api import dreams_predictions, PreTrainedModel\n",
    "from dreams.models.heads.heads import BinClassificationHead\n",
    "from dreams.utils.io import append_to_stem\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from dreams.utils.dformats import DataFormatA\n",
    "from dreams.utils.data import MSData\n",
    "from dreams.utils.io import append_to_stem\n",
    "import torch\n",
    "\n",
    "def find_PFAS(in_pth):\n",
    "    # in_pth = 'data/teo/<in_file>.mgf'  # or .mzML\n",
    "    # out_csv_pth = 'data/teo/<in_file>_f_preds.csv'\n",
    "\n",
    "    # in_pth = Path('/teamspace/studios/this_studio/SLI23_040.mzML')\n",
    "\n",
    "    n_highest_peaks = 60\n",
    "\n",
    "    print(f'Processing {in_pth}...')\n",
    "\n",
    "    # Load data\n",
    "    try:\n",
    "        msdata = MSData.from_mzml(in_pth, verbose_parser=True)\n",
    "    except ValueError as e:\n",
    "        print(f'Skipping {in_pth} because of {e}.')\n",
    "        return\n",
    "\n",
    "    # Get spectra (m/z and inetsnity arrays) and precursor m/z values from the input dataset\n",
    "    spectra = msdata['spectrum']\n",
    "    prec_mzs = msdata['precursor_mz']\n",
    "\n",
    "    # Ref: https://dreams-docs.readthedocs.io/en/latest/tutorials/spectral_quality.html\n",
    "    # Subject each spectrum to spectral quality checks\n",
    "    dformat = DataFormatA()\n",
    "    quality_lvls = [dformat.val_spec(s, p, return_problems=True) for s, p in zip(spectra, prec_mzs)]\n",
    "\n",
    "    # Check how many spectra passed all filters (`All checks passed`) and how many spectra did not pass some of the filters\n",
    "    print(pd.Series(quality_lvls).value_counts())\n",
    "\n",
    "    # Define path for output high-quality file\n",
    "    hq_pth = append_to_stem(in_pth, 'high_quality').with_suffix('.hdf5')\n",
    "\n",
    "    # Pick only high-quality spectra and save them to `hq_pth`\n",
    "    msdata.form_subset(\n",
    "        idx=np.where(np.array(quality_lvls) == 'All checks passed')[0],\n",
    "        out_pth=hq_pth\n",
    "    )\n",
    "\n",
    "    # Try reading the new file\n",
    "    msdata_hq = MSData.load(hq_pth)\n",
    "\n",
    "    # Compute fluorine probabilties\n",
    "    df = msdata_hq.to_pandas()\n",
    "    \n",
    "    f_preds = dreams_predictions(\n",
    "        spectra=msdata_hq,\n",
    "        model_ckpt=model,\n",
    "        n_highest_peaks=n_highest_peaks\n",
    "    )\n",
    "\n",
    "    df[f'PFAS_preds'] = torch.sigmoid(torch.from_numpy(f_preds)).cpu().numpy()\n",
    "\n",
    "\n",
    "    # Store predictions\n",
    "    # df.to_csv(append_to_stem(in_pth, 'PFAS_preds').with_suffix('.csv'), index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def scan_and_run_pfas(directory, output_csv=\"pfas_hits.csv\", threshold=0.95):\n",
    "    \"\"\"\n",
    "    Scan directory for .mzML files, run find_PFAS() on each, \n",
    "    filter predictions, aggregate results, and save to CSV.\n",
    "    \"\"\"\n",
    "    all_hits = []   # list of DataFrames\n",
    "\n",
    "    # Loop over all files in directory\n",
    "    for fname in os.listdir(directory):\n",
    "        if fname.lower().endswith(\".mzml\"):\n",
    "            file_path = os.path.join(directory, fname)\n",
    "            print(f\"Processing: {file_path}\")\n",
    "\n",
    "            try:\n",
    "                # Call your PFAS detection function\n",
    "                df = find_PFAS(Path(file_path))   # must return a pandas DataFrame\n",
    "\n",
    "                # Confirm required column exists\n",
    "                if \"PFAS_preds\" not in df.columns:\n",
    "                    print(f\"  ‚ö† Warning: no PFAS_preds column in {fname}, skipping.\")\n",
    "                    continue\n",
    "\n",
    "                # Filter based on threshold\n",
    "                df_hits = df[df[\"PFAS_preds\"] >= threshold].copy()\n",
    "\n",
    "                # Add file path reference\n",
    "                df_hits[\"file_path\"] = file_path\n",
    "\n",
    "                # Only append if non-empty\n",
    "                if not df_hits.empty:\n",
    "                    all_hits.append(df_hits)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error processing {fname}: {e}\")\n",
    "\n",
    "    # Combine all records\n",
    "    if all_hits:\n",
    "        final_df = pd.concat(all_hits, ignore_index=True)\n",
    "        final_df.to_csv(output_csv, index=False)\n",
    "        print(f\"\\n‚ú® Done. Found {len(final_df)} PFAS-like entries.\")\n",
    "        print(f\"Output saved to: {output_csv}\")\n",
    "\n",
    "        return final_df\n",
    "    else:\n",
    "        print(\"\\nüö´ No PFAS candidates found in any file.\")\n",
    "        return pd.DataFrame()  # empty\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "output_csv = '/teamspace/studios/this_studio/mzML_files/pfas_hits.csv'\n",
    "final_results = scan_and_run_pfas(\"/teamspace/studios/this_studio/mzML_files/MSV000099052\", output_csv=output_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging NIST20 and MassSpecGym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Replace with your actual file path\n",
    "file_path = '/teamspace/studios/this_studio/MassSpecGym/NIST20_MoNA_A_all_with_F_Murcko_split_MCE_test_minimum_cols.pkl'\n",
    "\n",
    "# Load the pickle file\n",
    "nist20_df = pd.read_pickle(file_path)\n",
    "\n",
    "# Check the result\n",
    "nist20_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nist20_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where the 'ID' starts with \"NIST20\"\n",
    "nist20_df = nist20_df[nist20_df['ID'].str.startswith(\"NIST20\")].copy()\n",
    "\n",
    "nist20_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from massspecgym.utils import load_massspecgym\n",
    "massspec_df = load_massspecgym().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "massspec_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# -----------------------------\n",
    "# STEP 1: Preprocess nist20_df\n",
    "# -----------------------------\n",
    "nist20_df = nist20_df.copy()\n",
    "\n",
    "# Split 'PARSED PEAKS' into two columns\n",
    "nist20_df['mzs'] = nist20_df['PARSED PEAKS'].apply(lambda x: x[0])\n",
    "nist20_df['intensities'] = nist20_df['PARSED PEAKS'].apply(lambda x: x[1])\n",
    "\n",
    "# Build a MassSpec-compatible DataFrame from NIST20\n",
    "nist20_converted = pd.DataFrame({\n",
    "    'identifier': nist20_df['ID'],\n",
    "    'mzs': nist20_df['mzs'],\n",
    "    'intensities': nist20_df['intensities'],\n",
    "    'smiles': nist20_df['SMILES'],\n",
    "    'inchikey': None,  # Not available in NIST20\n",
    "    'formula': nist20_df['FORMULA'],\n",
    "    'precursor_formula': nist20_df['FORMULA'],  # Assume it's the same\n",
    "    'parent_mass': nist20_df['PRECURSOR M/Z'],  # Approximate\n",
    "    'precursor_mz': nist20_df['PRECURSOR M/Z'],\n",
    "    'adduct': '[M+H]+',\n",
    "    'instrument_type': None,\n",
    "    'collision_energy': None,\n",
    "    'fold': nist20_df['fold'],\n",
    "    'simulation_challenge': False  # NIST20 is real, not simulated\n",
    "})\n",
    "\n",
    "# -----------------------------\n",
    "# STEP 2: Normalize MassSpec df\n",
    "# -----------------------------\n",
    "expected_columns = [\n",
    "    'identifier', 'mzs', 'intensities', 'smiles', 'inchikey', 'formula', 'precursor_formula',\n",
    "    'parent_mass', 'precursor_mz', 'adduct', 'instrument_type',\n",
    "    'collision_energy', 'fold', 'simulation_challenge'\n",
    "]\n",
    "\n",
    "nist20_converted = nist20_converted[expected_columns]\n",
    "massspec_gym_df = massspec_df.copy()\n",
    "massspec_gym_df = massspec_gym_df[expected_columns]\n",
    "\n",
    "# -----------------------------\n",
    "# STEP 3: Merge the datasets\n",
    "# -----------------------------\n",
    "merged_df = pd.concat([massspec_gym_df, nist20_converted], ignore_index=True)\n",
    "\n",
    "# -----------------------------\n",
    "# STEP 4: Save merged dataset\n",
    "# -----------------------------\n",
    "# Save as TSV\n",
    "merged_df.to_pickle('merged_massspec_nist20.pkl')\n",
    "\n",
    "# Check result\n",
    "print(f\"Merged dataset shape: {merged_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Murcko Histogram Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Replace with your actual file path\n",
    "file_path = '/teamspace/studios/this_studio/files/merged_massspec_nist20_with_nist_new.tsv'\n",
    "\n",
    "df = pd.read_csv(file_path, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the result\n",
    "df.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the necessary libraries\n",
    "from rdkit import Chem\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from dreams.algorithms.murcko_hist import murcko_hist\n",
    "from dreams.utils.data import MSData, evaluate_split\n",
    "from dreams.utils.plots import init_plotting\n",
    "from dreams.definitions import *\n",
    "tqdm.pandas()\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = murcko_hist.murcko_hist(Chem.MolFromSmiles('O=C(O)[C@@H]1/N=C(\\SC1)c2sc3cc(O)ccc3n2'), show_mol_scaffold=True)\n",
    "print('Murcko histogram:', hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_us = df.drop_duplicates(subset=[SMILES]).copy()  # Uniquify SMILES\n",
    "\n",
    "# Compute Murcko histograms\n",
    "df_us['MurckoHist'] = df_us[SMILES].progress_apply(\n",
    "    lambda x: murcko_hist.murcko_hist(Chem.MolFromSmiles(x))\n",
    ")\n",
    "\n",
    "# Convert dictionaries to strings for easier handling\n",
    "df_us['MurckoHistStr'] = df_us['MurckoHist'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Num. unique SMILES:', df_us[SMILES].nunique(), 'Num. unique Murcko histograms:', df_us['MurckoHistStr'].nunique())\n",
    "print('Top 20 most common Murcko histograms:')\n",
    "df_us['MurckoHistStr'].value_counts()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by MurckoHistStr and aggregate\n",
    "df_gb = df_us.groupby('MurckoHistStr').agg(\n",
    "    count=(SMILES, 'count'),\n",
    "    smiles_list=(SMILES, list)\n",
    ").reset_index()\n",
    "\n",
    "# Convert MurckoHistStr to MurckoHist\n",
    "df_gb['MurckoHist'] = df_gb['MurckoHistStr'].apply(eval)\n",
    "\n",
    "# Sort by 'n' in descending order and reset index\n",
    "df_gb = df_gb.sort_values('count', ascending=False).reset_index(drop=True)\n",
    "\n",
    "df_gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_i = len(df_gb) // 2\n",
    "cum_val_mols = 0\n",
    "val_mols_frac = 0.15  # Approximately 15% of the molecules go to validation set\n",
    "val_idx, train_idx = [], []\n",
    "\n",
    "# Iterate from median to start, assigning molecules to train or val sets\n",
    "for i in range(median_i, -1, -1):\n",
    "    current_hist = df_gb.iloc[i]['MurckoHist']\n",
    "    is_val_subhist = any(\n",
    "        murcko_hist.are_sub_hists(current_hist, df_gb.iloc[j]['MurckoHist'], k=3, d=4)\n",
    "        for j in val_idx\n",
    "    )\n",
    "\n",
    "    if is_val_subhist:\n",
    "        train_idx.append(i)\n",
    "    else:\n",
    "        if cum_val_mols / len(df_us) <= val_mols_frac:\n",
    "            cum_val_mols += df_gb.iloc[i]['count']\n",
    "            val_idx.append(i)\n",
    "        else:\n",
    "            train_idx.append(i)\n",
    "\n",
    "# Add remaining indices to train set\n",
    "train_idx.extend(range(median_i + 1, len(df_gb)))\n",
    "assert(len(train_idx) + len(val_idx) == len(df_gb))\n",
    "\n",
    "# Map SMILES to their assigned fold\n",
    "smiles_to_fold = {}\n",
    "for i, row in df_gb.iterrows():\n",
    "    fold = 'val' if i in val_idx else 'train'\n",
    "    for smiles in row['smiles_list']:\n",
    "        smiles_to_fold[smiles] = fold\n",
    "df[FOLD] = df[SMILES].map(smiles_to_fold)\n",
    "\n",
    "# Display fold distributions\n",
    "print('Distribution of spectra:')\n",
    "display(df[FOLD].value_counts(normalize=True))\n",
    "print('Distribution of SMILES:')\n",
    "display(df.drop_duplicates(subset=[SMILES])[FOLD].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_res = evaluate_split(df, n_workers=4)\n",
    "init_plotting(figsize=(3, 3))\n",
    "sns.histplot(eval_res['val'], bins=100)\n",
    "plt.xlabel('Max Tanimoto similarity to training set')\n",
    "plt.ylabel('Num. validation set molecules')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "print('Num. unique inchikey:', df['inchikey'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t = df.groupby('inchikey').agg(\n",
    "    count=(SMILES, 'count')\n",
    ").reset_index()\n",
    "\n",
    "df_t = df_t.sort_values(by='count', ascending=False).reset_index()\n",
    "df_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_zero_peaks(mzs, intensities):\n",
    "    # Filter out zero values in either mz or intensity\n",
    "    filtered = [(mz, inten) for mz, inten in zip(mzs, intensities) if mz != 0 and inten != 0]\n",
    "    \n",
    "    if not filtered:\n",
    "        return [], []\n",
    "    \n",
    "    # Sort by mz\n",
    "    filtered.sort(key=lambda x: x[0])\n",
    "    \n",
    "    mzs_clean, intensities_clean = zip(*filtered)\n",
    "    return list(mzs_clean), list(intensities_clean)\n",
    "\n",
    "# Apply to entire DataFrame\n",
    "df[['mzs', 'intensities']] = df.apply(\n",
    "    lambda row: pd.Series(remove_zero_peaks(row['mzs'], row['intensities'])),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('merged_massspec_nist20_nist_new_with_fold.tsv', sep='\\t')\n",
    "import pandas as pd\n",
    "\n",
    "test_df = pd.read_csv('/teamspace/studios/this_studio/files/merged_massspec_nist20_nist_new_with_fold.tsv', sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t = test_df.groupby('fold').agg(\n",
    "    count=('fold', 'count')\n",
    ").reset_index()\n",
    "df_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect PFAS in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import rdchem\n",
    "\n",
    "# Definition of PFAS based on OECD: https://pubs.acs.org/doi/10.1021/acs.est.1c06896\n",
    "def is_pfas_oecd(smiles: str) -> int:\n",
    "    try:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            return 0\n",
    "\n",
    "        for atom in mol.GetAtoms():\n",
    "            if atom.GetAtomicNum() != 6:  # carbon only\n",
    "                continue\n",
    "\n",
    "            # neighbors\n",
    "            neigh = atom.GetNeighbors()\n",
    "            sym = [n.GetSymbol() for n in neigh]\n",
    "\n",
    "            num_F = sum(1 for s in sym if s == \"F\")\n",
    "            has_X  = any(s in (\"Cl\", \"Br\", \"I\") for s in sym)\n",
    "            has_H  = atom.GetTotalNumHs() > 0  # implicit + explicit Hs\n",
    "\n",
    "            # require sp3 and all single bonds (rules out alkenes like TFE)\n",
    "            is_sp3 = atom.GetHybridization() == rdchem.HybridizationType.SP3\n",
    "            all_single = all(\n",
    "                mol.GetBondBetweenAtoms(atom.GetIdx(), n.GetIdx()).GetBondType() == rdchem.BondType.SINGLE\n",
    "                for n in neigh\n",
    "            )\n",
    "\n",
    "            # CF3: at least 3 F neighbors; CF2: at least 2 F neighbors\n",
    "            if (num_F >= 3 or num_F >= 2) and is_sp3 and all_single and not has_H and not has_X:\n",
    "                # For CF2, make sure there's at least one non-F neighbor so it's truly \"-CF2-\"\n",
    "                if num_F >= 3:\n",
    "                    return 1\n",
    "                else:  # CF2\n",
    "                    nonF_neighbors = sum(1 for s in sym if s != \"F\")\n",
    "                    if nonF_neighbors >= 1:  # \"-CF2-\" has something other than F attached\n",
    "                        return 1\n",
    "\n",
    "        return 0\n",
    "    except Exception:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "\n",
    "# Load your dataframe\n",
    "df = pd.read_csv('/teamspace/studios/this_studio/files/merged_massspec_nist20_nist_new_with_fold.tsv', sep='\\t')\n",
    "\n",
    "# Add PFAS col\n",
    "df['is_PFAS'] = df['smiles'].apply(is_pfas_oecd)\n",
    "\n",
    "# View how many were identified\n",
    "print(f\"Identified {df['is_PFAS'].sum()} potential PFAS compounds out of {len(df)} total.\")\n",
    "\n",
    "#df.to_csv('merged_massspec_nist20_nist_new_with_pfas_fold.tsv', sep='\\t')\n",
    "\n",
    "# Optionally: get only the PFAS rows\n",
    "pfas_df = df[df['is_PFAS'] == 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem import Draw\n",
    "import random as r\n",
    "import pandas as pd\n",
    "\n",
    "unique_pfas_train = pfas_df[pfas_df['fold'] == 'train']['smiles'].unique()\n",
    "unique_pfas_val = pfas_df[pfas_df['fold'] == 'val']['smiles'].unique()\n",
    "print(f\"Train uniq PFAS = {len(unique_pfas_train)}, Val uniq PFAS = {len(unique_pfas_val)}\")\n",
    "\n",
    "pfas_train = len(pfas_df[pfas_df['fold'] == 'train'])\n",
    "pfas_val = len(pfas_df[pfas_df['fold'] == 'val'])\n",
    "print(f\"Train PFAS = {pfas_train}, Val PFAS = {pfas_val}\")\n",
    "\n",
    "\n",
    "print(f\"Drawing a random molecule from train\")\n",
    "smiles_list = unique_pfas_train.tolist()\n",
    "m = Chem.MolFromSmiles(r.choice(smiles_list))\n",
    "img = Draw.MolToImage(m)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pfas_df.to_csv('pfas_only_records.csv', sep='\\t')\n",
    "#only_val_df = pfas_df[pfas_df['fold'] == 'val']\n",
    "#only_val_df.to_csv('pfas_only_records_val.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "pfas_dataset = TestMassSpecDataset(\n",
    "    spec_transform=SpecTokenizer(n_peaks=60),\n",
    "    mol_transform = MolToHalogensVector(),\n",
    "    pth='/teamspace/studios/this_studio/pfas_only_records.tsv'\n",
    ")\n",
    "\n",
    "print(len(pfas_dataset))\n",
    "\n",
    "# Init data module\n",
    "pfas_data_module = MassSpecDataModule(\n",
    "    dataset=pfas_dataset,\n",
    "    batch_size=64,\n",
    "    num_workers=1\n",
    ")\n",
    "pfas_data_module.setup()\n",
    "\n",
    "ckpt_path = '/teamspace/studios/this_studio/HalogenDetection-FocalLoss-MergedMassSpecNIST20/opi4lx8s/checkpoints/epoch=0-step=8920.ckpt'\n",
    "model = HalogenDetectorDreamsTest.load_from_checkpoint(ckpt_path)\n",
    "\n",
    "\n",
    "trainer = Trainer(accelerator=\"auto\", devices=\"auto\", max_epochs=1)\n",
    "trainer.validate(model=model, datamodule=pfas_data_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Fluorine Model\n",
    "## threshold - 0.9\n",
    "## /teamspace/studios/this_studio/HalogenDetection-FocalLoss-MergedMassSpecNIST20/opi4lx8s/checkpoints/epoch=0-step=8920.ckpt\n",
    "## PFAS Model\n",
    "## threshold - 0.9\n",
    "## /teamspace/studios/this_studio/PFASDetection-FocalLoss-MergedMassSpecNIST20OECDWith_PFASExceptions/7zi45xm4/checkpoints/epoch=0-step=8920.ckpt\n",
    "\n",
    "# Path to your checkpoint file\n",
    "ckpt_path = '/teamspace/studios/this_studio/MassSpecGym/notebooks/fluorine_model_nohead.ckpt'\n",
    "#ckpt_path = '/teamspace/studios/this_studio/HalogenDetection-FocalLoss-MergedMassSpecNIST20/opi4lx8s/checkpoints/epoch=0-step=8920.ckpt'\n",
    "\n",
    "# Load the checkpoint\n",
    "checkpoint = torch.load(ckpt_path, map_location='cpu')\n",
    "\n",
    "# Print available metadata keys\n",
    "print(\"Checkpoint keys:\")\n",
    "print(checkpoint.keys())\n",
    "\n",
    "# Optionally, display specific metadata if available\n",
    "if 'state_dict' in checkpoint:\n",
    "    print(f\"Model state_dict {checkpoint['hyper_parameters']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your checkpoint file\n",
    "# Fluorine Model\n",
    "## threshold - 0.9\n",
    "import torch\n",
    "from collections import OrderedDict\n",
    "\n",
    "ckpt_path = '/teamspace/studios/this_studio/HalogenDetection-FocalLoss-MergedMassSpecNIST20/opi4lx8s/checkpoints/epoch=0-step=8920.ckpt'\n",
    "\n",
    "# Load the Fluorine model\n",
    "model = torch.load(ckpt_path, map_location='cpu')\n",
    "\n",
    "new_model = dict()\n",
    "\n",
    "# copy the old model\n",
    "for k, v in model.items():\n",
    "    new_model[k] = v\n",
    "\n",
    "# Inspect keys\n",
    "state_dict = new_model['state_dict']  # may contain 'state_dict', 'model_state_dict', etc.\n",
    "\n",
    "# Remove head layer (lin_out)\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in state_dict.items():\n",
    "    if \"lin_out\" not in k:  # or \"fc\" if named differently\n",
    "        new_state_dict[k] = v\n",
    "    else:\n",
    "        print(\"skipping lin_out layer\")\n",
    "\n",
    "new_model['state_dict'] = new_state_dict\n",
    "\n",
    "# Save modified checkpoint\n",
    "torch.save(new_model, \"fluorine_model_nohead.ckpt\")\n",
    "\n",
    "print(f\"‚úÖ Stripped last layer and saved new checkpoint.{new_state_dict}\",)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "import pandas as pd\n",
    "df_unique = pd.read_pickle('/teamspace/studios/this_studio/files/merged_massspec_nist20.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_massspec = df_unique[df_unique[\"identifier\"].str.startswith(\"MassSpecGym\")]\n",
    "df_nist = df_unique[df_unique[\"identifier\"].str.startswith(\"NIST20\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inchi_ms = df_massspec[\"inchikey\"].nunique()\n",
    "num_inchi_nist = df_nist[\"inchikey\"].nunique()\n",
    "num_smil_ms = df_massspec[\"smiles\"].nunique()\n",
    "num_smil_nist = df_nist[\"smiles\"].nunique()\n",
    "\n",
    "print(f\"num_inchi_ms = {num_inchi_ms}, num_inchi_nist = {num_inchi_nist}, num_smil_ms = {num_smil_ms}, num_smil_nist = {num_smil_nist}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import urllib\n",
    "import json\n",
    "import time\n",
    "import ase\n",
    "import rdkit\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from tqdm import tqdm\n",
    "from rdkit import DataStructs, RDLogger\n",
    "from rdkit.Chem import AllChem as Chem\n",
    "from rdkit.Chem import rdchem, Draw, rdMolDescriptors, QED, Crippen, Lipinski\n",
    "from rdkit.Chem.Draw import rdMolDraw2D\n",
    "from rdkit.Chem.MACCSkeys import GenMACCSKeys\n",
    "from rdkit.Contrib.SA_Score import sascorer\n",
    "from rdkit.Chem.Descriptors import ExactMolWt\n",
    "from collections import defaultdict\n",
    "from typing import List, Optional\n",
    "from pathlib import Path\n",
    "import dreams.utils.misc as utils\n",
    "\n",
    "\n",
    "def show_mols(mols, legends='new_indices', smiles_in=None, svg=False, sort_by_legend=False, max_mols=500,\n",
    "              legend_float_decimals=4, mols_per_row=6, save_pth: Optional[Path] = None):\n",
    "    \"\"\"\n",
    "    Returns svg image representing a grid of skeletal structures of the given molecules\n",
    "\n",
    "    :param mols: list of rdkit molecules\n",
    "    :param legends: list of labels for each molecule, length must be equal to the length of mols. \n",
    "                   Can be 'new_indices' for default numbering, 'masses' for molecular weights,\n",
    "                   or a list of custom labels\n",
    "    :param smiles_in: True - SMILES inputs, False - RDKit mols, None - determine automatically\n",
    "    :param svg: True - return svg image, False - return png image\n",
    "    :param sort_by_legend: True - sort molecules by legend values\n",
    "    :param max_mols: maximum number of molecules to show\n",
    "    :param legend_float_decimals: number of decimal places to show for float legends\n",
    "    :param mols_per_row: number of molecules per row to show\n",
    "    :param save_pth: path to save the .svg image to\n",
    "    \"\"\"\n",
    "    disable_rdkit_log()\n",
    "\n",
    "    if smiles_in is None:\n",
    "        smiles_in = all(isinstance(e, str) for e in mols)\n",
    "\n",
    "    if smiles_in:\n",
    "        mols = [Chem.MolFromSmiles(e) for e in mols]\n",
    "\n",
    "    if isinstance(legends, str):\n",
    "        if legends == 'new_indices':\n",
    "            legends = list(range(len(mols)))\n",
    "        elif legends == 'masses':\n",
    "            legends = [ExactMolWt(m) for m in mols]\n",
    "    elif callable(legends):\n",
    "        legends = [legends(e) for e in mols]\n",
    "    elif isinstance(legends, (list, np.ndarray, pd.Series)):\n",
    "        legends = [str(l) for l in legends]\n",
    "    else:\n",
    "        raise ValueError(f'Invalid legends type: {type(legends)}. Must be a list, numpy array, pandas series or'\n",
    "                         '\"new_indices\" or \"masses\".')\n",
    "\n",
    "    if sort_by_legend:\n",
    "        idx = np.argsort(legends).tolist()\n",
    "        legends = [legends[i] for i in idx]\n",
    "        mols = [mols[i] for i in idx]\n",
    "\n",
    "    legends = [f'{l:.{legend_float_decimals}f}' if isinstance(l, float) else str(l) for l in legends]\n",
    "\n",
    "    img = Draw.MolsToGridImage(mols, maxMols=max_mols, legends=legends, molsPerRow=min(max_mols, mols_per_row),\n",
    "                         useSVG=svg, returnPNG=False)\n",
    "\n",
    "    if save_pth:\n",
    "        with open(save_pth, 'w') as f:\n",
    "            f.write(img.data)\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "def mol_to_formula(mol, as_dict=False):\n",
    "    formula = rdMolDescriptors.CalcMolFormula(mol)\n",
    "    return formula_to_dict(formula) if as_dict else formula\n",
    "\n",
    "\n",
    "def smiles_to_formula(s, as_dict=False, invalid_mol_smiles=''):\n",
    "    mol = Chem.MolFromSmiles(s)\n",
    "    if not mol and invalid_mol_smiles is not None:\n",
    "        f = invalid_mol_smiles\n",
    "    else:\n",
    "        f = rdMolDescriptors.CalcMolFormula(mol)\n",
    "    if as_dict:\n",
    "        f = formula_to_dict(f)\n",
    "    return f\n",
    "\n",
    "\n",
    "class MolPropertyCalculator:\n",
    "    def __init__(self):\n",
    "        # Estimates of min and max values from the training part of MoNA and NIST20 Murcko histograms split\n",
    "        self.min_maxs = {\n",
    "            'AtomicLogP': {'min': -13.054800000000025, 'max': 26.849200000000053},\n",
    "            'NumHAcceptors': {'min': 0.0, 'max': 36.0},\n",
    "            'NumHDonors': {'min': 0.0, 'max': 20.0},\n",
    "            'PolarSurfaceArea': {'min': 0.0, 'max': 585.0300000000002},\n",
    "            'NumRotatableBonds': {'min': 0.0, 'max': 68.0},\n",
    "            'NumAromaticRings': {'min': 0.0, 'max': 8.0},\n",
    "            'NumAliphaticRings': {'min': 0.0, 'max': 22.0},\n",
    "            'FractionCSP3': {'min': 0.0, 'max': 1.0},\n",
    "            'QED': {'min': 0.0, 'max': 1.0},  # 'QED': {'min': 0.008950206972239864, 'max': 0.9479380820623227},\n",
    "            'SyntheticAccessibility': {'min': 1.0, 'max': 10.0},  # 'SyntheticAccessibility': {'min': 1.0549172379947862, 'max': 8.043981630210263},\n",
    "            'BertzComplexity': {'min': 2.7548875021634682, 'max': 3748.669248605835}\n",
    "        }\n",
    "        self.prop_names = list(self.min_maxs.keys())\n",
    "\n",
    "    def mol_to_props(self, mol, min_max_norm=False):\n",
    "        props = {\n",
    "            'AtomicLogP': Crippen.MolLogP(mol),\n",
    "            'NumHAcceptors': Lipinski.NumHAcceptors(mol),\n",
    "            'NumHDonors': Lipinski.NumHDonors(mol),\n",
    "            'PolarSurfaceArea': rdMolDescriptors.CalcTPSA(mol),\n",
    "            'NumRotatableBonds': Lipinski.NumRotatableBonds(mol),\n",
    "            'NumAromaticRings': Lipinski.NumAromaticRings(mol),\n",
    "            'NumAliphaticRings': Lipinski.NumAliphaticRings(mol),\n",
    "            'FractionCSP3': Lipinski.FractionCSP3(mol),\n",
    "            'QED': QED.qed(mol),\n",
    "            'SyntheticAccessibility': sascorer.calculateScore(mol),\n",
    "            'BertzComplexity': rdkit.Chem.GraphDescriptors.BertzCT(mol)\n",
    "        }\n",
    "        if min_max_norm:\n",
    "            props = self.normalize_props(props)\n",
    "        return props\n",
    "\n",
    "    def normalize_prop(self, prop, prop_name):\n",
    "        return (prop - self.min_maxs[prop_name]['min']) / (self.min_maxs[prop_name]['max'] - self.min_maxs[prop_name]['min'])\n",
    "\n",
    "    def denormalize_prop(self, prop, prop_name, do_not_add_min=False):\n",
    "        res = prop * (self.min_maxs[prop_name]['max'] - self.min_maxs[prop_name]['min'])\n",
    "        if not do_not_add_min:\n",
    "            res = res + self.min_maxs[prop_name]['min']\n",
    "        return res\n",
    "\n",
    "    def normalize_props(self, props):\n",
    "        return {k: self.normalize_prop(v, k) for k, v in props.items()}\n",
    "\n",
    "    def denormalize_props(self, props):\n",
    "        return {k: self.denormalize_prop(v, k) for k, v in props.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.prop_names)\n",
    "\n",
    "\n",
    "def formula_to_dict(formula):\n",
    "    \"\"\"\n",
    "    Transforms chemical formula string to dictionary mapping elements to their frequencies\n",
    "    e.g. 'C15H24' -> {'C': 15, 'H': 24}\n",
    "    \"\"\"\n",
    "    elem_count = defaultdict(int)\n",
    "    #try:\n",
    "    formula = formula.replace('+', '').replace('-', '').replace('[', '').replace(']', '')\n",
    "    formula_counts = ase.formula.Formula(formula)\n",
    "    formula_counts = formula_counts.count().items()\n",
    "    for k, v in formula_counts:\n",
    "        elem_count[k] += v\n",
    "    #except Exception as e:\n",
    "    #    print(f'Invalid formula: {formula} ({e.__class__.__name__})')\n",
    "\n",
    "    return elem_count\n",
    "\n",
    "\n",
    "def rdkit_fp(mol, fp_size=4096):\n",
    "    \"\"\"Default RDKit fingerprint.\"\"\"\n",
    "    return Chem.RDKFingerprint(mol, fpSize=fp_size)\n",
    "\n",
    "\n",
    "def tanimoto_sim(fp1, fp2):\n",
    "    \"\"\"Default RDKit Tanimoto distance.\"\"\"\n",
    "    return DataStructs.TanimotoSimilarity(fp1, fp2)\n",
    "\n",
    "\n",
    "def rdkit_mol_sim(m1, m2, fp_size=4096):\n",
    "    \"\"\"Default RDKit Tanimoto distance on default RDKit fingerprint.\"\"\"\n",
    "    return tanimoto_sim(rdkit_fp(m1, fp_size=fp_size), rdkit_fp(m2, fp_size=fp_size))\n",
    "\n",
    "\n",
    "def rdkit_smiles_sim(s1, s2, fp_size=4096):\n",
    "    \"\"\"Default RDKit Tanimoto distance on default RDKit fingerprint.\"\"\"\n",
    "    return rdkit_mol_sim(Chem.MolFromSmiles(s1), Chem.MolFromSmiles(s2), fp_size=fp_size)\n",
    "\n",
    "\n",
    "def morgan_fp(mol, binary=True, fp_size=4096, radius=2, as_numpy=True):\n",
    "    if binary:\n",
    "        fp = Chem.GetMorganFingerprintAsBitVect(mol, radius=radius, nBits=fp_size)\n",
    "    else:\n",
    "        fp = Chem.GetHashedMorganFingerprint(mol, radius=radius, nBits=fp_size)\n",
    "\n",
    "    if as_numpy:\n",
    "        return rdkit_fp_to_np(fp)\n",
    "    return fp\n",
    "\n",
    "\n",
    "def maccs_fp(mol, as_numpy=True):\n",
    "    \"\"\"\n",
    "    NOTE: Since indexing of MACCS keys starts from 1, when converting to numpy array with `as_numpy`, the first element\n",
    "          is removed, so the resulting array has 166 elements instead of 167.\n",
    "    \"\"\"\n",
    "    fp = GenMACCSKeys(mol)\n",
    "    if as_numpy:\n",
    "        return rdkit_fp_to_np(fp)[1:]\n",
    "    return fp\n",
    "\n",
    "\n",
    "def fp_func_from_str(s):\n",
    "    \"\"\"\n",
    "    :param s: E.g. \"fp_rdkit_2048\", \"fp_rdkit_2048\" or \"fp_maccs_166\".\n",
    "    \"\"\"\n",
    "    _, fp_type, n_bits = s.split('_')\n",
    "    n_bits = int(n_bits)\n",
    "    if fp_type == 'rdkit':\n",
    "        return lambda mol: np.array(rdkit_fp(mol, fp_size=n_bits), dtype=float)\n",
    "    elif fp_type == 'morgan':\n",
    "        return lambda mol: morgan_fp(mol, fp_size=n_bits).astype(float, copy=False)\n",
    "    elif fp_type == 'maccs':\n",
    "        return lambda mol: maccs_fp(mol).astype(float, copy=False)\n",
    "    else:\n",
    "        raise ValueError(f'Invalid fingerprint function name: \"{s}\".')\n",
    "\n",
    "\n",
    "def morgan_mol_sim(m1, m2, fp_size=4096, radius=2):\n",
    "    return tanimoto_sim(\n",
    "        morgan_fp(m1, fp_size=fp_size, radius=radius, as_numpy=False),\n",
    "        morgan_fp(m2, fp_size=fp_size, radius=radius, as_numpy=False)\n",
    "    )\n",
    "\n",
    "\n",
    "def morgan_smiles_sim(s1, s2, fp_size=4096, radius=2):\n",
    "    return morgan_mol_sim(Chem.MolFromSmiles(s1), Chem.MolFromSmiles(s2), fp_size=fp_size, radius=radius)\n",
    "\n",
    "\n",
    "def rdkit_fp_to_np(fp):\n",
    "    fp_np = np.zeros((0,), dtype=np.int32)\n",
    "    DataStructs.ConvertToNumpyArray(fp, fp_np)\n",
    "    return fp_np\n",
    "\n",
    "\n",
    "def np_to_rdkit_fp(fp):\n",
    "    fp = fp.round().astype(int, copy=False)\n",
    "    bitstring = ''.join(fp.astype(str))\n",
    "    return DataStructs.cDataStructs.CreateFromBitString(bitstring)\n",
    "\n",
    "\n",
    "def mol_to_inchi14(mol: Chem.Mol):\n",
    "    return Chem.MolToInchiKey(mol).split('-')[0]\n",
    "\n",
    "\n",
    "def smiles_to_inchi14(s):\n",
    "    return mol_to_inchi14(Chem.MolFromSmiles(s))\n",
    "\n",
    "\n",
    "def generate_fragments(mol: Chem.Mol, max_cuts: int = None):\n",
    "    \"\"\"\n",
    "    Generates all possible fragments of a molecule up to a certain number of bond cuts or without the restriction if\n",
    "    `max_cuts` is not specified.\n",
    "\n",
    "    :param mol: an RDKit molecule object\n",
    "    :param max_cuts: the maximum number of bonds to cut\n",
    "    :return a set of RDKit Mol objects representing all possible fragments\n",
    "    \"\"\"\n",
    "\n",
    "    bonds = mol.GetBonds()\n",
    "    # bonds = [bond for bond in bonds if bond.GetBondType() in [rdchem.BondType.SINGLE, rdchem.BondType.DOUBLE]]\n",
    "    fragments = set()\n",
    "    for i in range(1, len(bonds) + 1):\n",
    "\n",
    "        if max_cuts and i > max_cuts:\n",
    "            break\n",
    "\n",
    "        for combination in itertools.combinations(bonds, i):\n",
    "            new_mol = rdchem.RWMol(mol)\n",
    "            for bond in combination:\n",
    "                new_mol.RemoveBond(bond.GetBeginAtomIdx(), bond.GetEndAtomIdx())\n",
    "\n",
    "            # Update properties such as ring membership after changing the molecule's structure.\n",
    "            for fragment in Chem.GetMolFrags(new_mol, asMols=True, sanitizeFrags=False):\n",
    "                fragments.add(Chem.MolToSmiles(fragment))\n",
    "\n",
    "    fragments = [Chem.MolFromSmiles(f) for f in fragments]\n",
    "    return [f for f in fragments if f is not None]\n",
    "\n",
    "\n",
    "def generate_spectrum(mol: Chem.Mol, prec_mz: float = None, fragments: List = None, max_cuts: int = None):\n",
    "    \"\"\"\n",
    "    Generates an MS/MS spectrum by exhaustively simulating the m/z values of theoretical fragments of a given molecule.\n",
    "    The algorithm is very simplistic since it considers only subgraph-like fragments, does not consider isotopes, etc.\n",
    "\n",
    "    :param mol: An RDKit molecule object.\n",
    "    :param prec_mz: The m/z value of a molecule. If not specified, it is calculated as the sum of the\n",
    "                    exact molecular weight of the molecule and 1.\n",
    "    :param fragments: A list of RDKit Mol objects representing pre-generated fragments of the molecule. If not specified,\n",
    "                     the function will generate the fragments automatically.\n",
    "    :param max_cuts: The maximum number of bonds to cut when generating fragments. If not specified, all possible\n",
    "                     fragments will be generated without any restriction on the number of cuts.\n",
    "    :return: A spectrum represented as a numpy array with two columns: m/z values and their respective intensities.\n",
    "    \"\"\"\n",
    "\n",
    "    # Simulate the m/z of \"protonated adduct\"\n",
    "    if not prec_mz:\n",
    "        prec_mz = ExactMolWt(mol) + 1\n",
    "\n",
    "    # Fragment molecule\n",
    "    if not fragments:\n",
    "        fragments = generate_fragments(mol, max_cuts=max_cuts)\n",
    "\n",
    "    # Simulate spectrum\n",
    "    masses = np.round(np.array([prec_mz - ExactMolWt(f) for f in fragments]))\n",
    "    ins, mzs = np.histogram(masses, bins=np.arange(0, np.ceil(max(masses)), 1))\n",
    "    spec = np.stack([mzs[1:], ins]).T\n",
    "\n",
    "    return spec\n",
    "\n",
    "\n",
    "def closest_mz_frags(query_mz, frags, n=1, mass_shift=1, return_masses=False, print_masses=True):\n",
    "    masses = [ExactMolWt(f) + mass_shift for f in frags]\n",
    "    idx = utils.get_closest_values(masses, query_mz, n=n, return_idx=True)\n",
    "    frags, masses = [frags[i] for i in idx], [masses[i] for i in idx]\n",
    "    if n == 1:\n",
    "        frags, masses = frags[0], masses[0]\n",
    "    if print_masses:\n",
    "        print(masses)\n",
    "    if return_masses:\n",
    "        return frags, masses\n",
    "    return frags\n",
    "\n",
    "\n",
    "def disable_rdkit_log():\n",
    "    lg = RDLogger.logger()\n",
    "    lg.setLevel(RDLogger.CRITICAL)\n",
    "\n",
    "\n",
    "def np_classify(smiles: List[str], progress_bar=True, sleep_each_n_requests=100):\n",
    "    np_classes = []\n",
    "    for i, s in enumerate(tqdm(smiles) if progress_bar else smiles):\n",
    "        if i % sleep_each_n_requests == 0 and i > 0:\n",
    "            time.sleep(1)\n",
    "        print(s)\n",
    "        with urllib.request.urlopen(f'https://npclassifier.ucsd.edu/classify?smiles={urllib.parse.quote(s)}') as url:\n",
    "            res = json.load(url)\n",
    "            for k in list(res.keys()):\n",
    "                if 'fp' in k:\n",
    "                    res.pop(k)\n",
    "            np_classes.append(res)\n",
    "    return np_classes\n",
    "\n",
    "\n",
    "def mol_to_img_str(mol, svg_size=200):\n",
    "    \"\"\"\n",
    "    Supposed to be used with `pyvis` for showing molecule images as graph nodes.\n",
    "    \"\"\"\n",
    "    buffered = BytesIO()\n",
    "    d2d = rdMolDraw2D.MolDraw2DSVG(svg_size, svg_size)\n",
    "    opts = d2d.drawOptions()\n",
    "    opts.clearBackground = False\n",
    "    d2d.DrawMolecule(mol)\n",
    "    d2d.FinishDrawing()\n",
    "    img_str = d2d.GetDrawingText()\n",
    "    buffered.write(str.encode(img_str))\n",
    "    img_str = base64.b64encode(buffered.getvalue())\n",
    "    img_str = f\"data:image/svg+xml;base64,{repr(img_str)[2:-1]}\"\n",
    "    return img_str\n",
    "\n",
    "\n",
    "def formula_is_carbohydrate(formula):\n",
    "    return set(formula.keys()) <= {'C', 'H', 'O'}\n",
    "\n",
    "\n",
    "def formula_is_halogenated(formula):\n",
    "    return sum([(formula[e] if e in formula else 0) for e in ['F', 'Cl', 'Br', 'I']]) > 0\n",
    "\n",
    "\n",
    "def formula_type(f):\n",
    "    if isinstance(f, str):\n",
    "        f = formula_to_dict(f)\n",
    "\n",
    "    if not f:\n",
    "        return 'No formula'\n",
    "    elif formula_is_carbohydrate(f):\n",
    "        return 'Carbohydrate'\n",
    "    elif set(f.keys()) <= {'C', 'H', 'O', 'N'}:\n",
    "        return 'Carbohydrate with nitrogen'\n",
    "    elif set(f.keys()) <= {'C', 'H', 'O', 'N', 'S'} and 'N' in f and 'S' in f:\n",
    "        return 'Carbohydrate with nitrogen and sulfur'\n",
    "    elif formula_is_halogenated(f):\n",
    "        return 'Compound with halogens'\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "\n",
    "def get_mol_mass(mol):\n",
    "    return ExactMolWt(mol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_massspec = df_unique[df_unique[\"identifier\"].str.startswith(\"MassSpecGym\")]\n",
    "#df_nist = df_unique[df_unique[\"identifier\"].str.startswith(\"NIST20\")]\n",
    "#df_unique = pd.read_pickle('merged_massspec_nist20.pkl')\n",
    "\n",
    "df_nist['inchikey'] = df_nist['smiles'].apply(smiles_to_inchi14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inchi_ms = df_massspec[\"inchikey\"].nunique()\n",
    "num_inchi_nist = df_nist[\"inchikey\"].nunique()\n",
    "print(\"NIST unique # inchikeys: \" + str(num_inchi_nist))\n",
    "print(\"MassSpecGym unique # inchikeys: \" + str(num_inchi_ms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overlap our PFAS training and PFAS suspect list from data.gov\n",
    "import pandas as pd\n",
    "\n",
    "# Load both TSV files\n",
    "df_records = pd.read_csv(\"/teamspace/studios/this_studio/files/pfas_only_records.tsv\", sep='\\t')\n",
    "df_suspects = pd.read_csv(\"/teamspace/studios/this_studio/files/PFAS_suspect_list_data_gov.tsv\", sep='\\t')\n",
    "\n",
    "# Preview column names\n",
    "print(\"Records columns:\", df_records.columns.tolist())\n",
    "print(\"Suspects columns:\", df_suspects.columns.tolist())\n",
    "\n",
    "# Standardize column names\n",
    "smiles_records = df_records[df_records['fold'] == 'train']['smiles'].dropna().str.strip().unique()\n",
    "smiles_suspects = df_suspects['SMILES'].dropna().str.strip().unique()\n",
    "\n",
    "# Convert to sets for comparison\n",
    "set_records = set(smiles_records)\n",
    "set_suspects = set(smiles_suspects)\n",
    "\n",
    "# Find overlap\n",
    "overlap = set_suspects.intersection(set_records)\n",
    "\n",
    "# Report results\n",
    "print(f\"Total in PFAS_Suspect_List: {len(set_suspects)}\")\n",
    "print(f\"Total in pfas_only_records: {len(set_records)}\")\n",
    "print(f\"Overlapping SMILES: {len(overlap)}\")\n",
    "\n",
    "for smile in sorted(overlap):\n",
    "        print(smile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "\n",
    "# Your (corrected) SMILES string\n",
    "smiles = \"C(=O)(C(C(C(C(C(C(C(F)(F)F)(F)F)(F)F)(F)F)(F)F)(F)F)(F)F)O\"\n",
    "\n",
    "# Create RDKit molecule object\n",
    "mol = Chem.MolFromSmiles(smiles)\n",
    "\n",
    "if mol is None:\n",
    "    raise ValueError(\"SMILES string is invalid or could not be parsed.\")\n",
    "\n",
    "# Compute 2D coordinates for drawing\n",
    "Chem.rdDepictor.Compute2DCoords(mol)\n",
    "\n",
    "# Draw the molecule to a PNG file\n",
    "Draw.MolToFile(mol, \"molecule.png\", size=(400, 400))\n",
    "\n",
    "print(\"Saved structure as molecule.png\")\n",
    "\n",
    "# Create RDKit molecule object\n",
    "mol = Chem.MolFromSmiles(smiles)\n",
    "\n",
    "if mol is None:\n",
    "    raise ValueError(\"SMILES string is invalid or could not be parsed.\")\n",
    "\n",
    "# Compute 2D coordinates for drawing\n",
    "Chem.rdDepictor.Compute2DCoords(mol)\n",
    "\n",
    "# Draw the molecule to a PNG file\n",
    "Draw.MolToFile(mol, \"molecule.png\", size=(400, 400))\n",
    "\n",
    "print(\"Saved structure as molecule.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "\n",
    "# Your SMILES string\n",
    "smiles = \"O=P(O)(O)OP(=O)(O)OC/C=C(/CC\\C=C(/C)CC\\C=C(/C)CC\\C=C(/C)C)C\"   # ethanol\n",
    "\n",
    "# Convert SMILES ‚Üí RDKit molecule\n",
    "mol = Chem.MolFromSmiles(smiles)\n",
    "\n",
    "# Draw molecule (returns a PIL image)\n",
    "img = Draw.MolToImage(mol, size=(600, 600))\n",
    "\n",
    "# Show inline (Jupyter) or save if needed\n",
    "img.show()\n",
    "# img.save(\"molecule.png\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
